#!/usr/bin/env python3
# encoding: utf-8
"""
eBPFæ•°æ®åˆ†æžå·¥å…·ä¸»ç¨‹åº
æä¾›æ•°æ®åŠ è½½ã€åˆ†æžå’Œå¯¹æ¯”åŠŸèƒ½
é€‚é…æ–°çš„èšåˆç»Ÿè®¡æ•°æ®æ ¼å¼
"""

import argparse
import logging
import os
import socket
import sys
from io import StringIO
from typing import Optional

import pandas as pd

from data_utils import (
    safe_read_csv
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def capture_output_to_file(monitor_type_func):
    """è£…é¥°å™¨ï¼šæ•èŽ·printè¾“å‡ºå¹¶ä¿å­˜åˆ°æ–‡ä»¶"""

    def wrapper(self, date_str: str):
        # æå–ç›‘æŽ§å™¨ç±»åž‹å
        monitor_type = monitor_type_func.__name__.replace('analyze_', '')

        # æ•èŽ·è¾“å‡º
        old_stdout = sys.stdout
        sys.stdout = output_buffer = StringIO()

        try:
            # æ‰§è¡Œåˆ†æžå‡½æ•°
            monitor_type_func(self, date_str)

            # èŽ·å–è¾“å‡ºå†…å®¹
            content = output_buffer.getvalue()

            # æ¢å¤stdout
            sys.stdout = old_stdout

            # ä¿å­˜åˆ°æ–‡ä»¶
            if content.strip():
                self._save_report(monitor_type, date_str, content)
                # è·³è¿‡æ‰“å°åˆ°æŽ§åˆ¶å°
                # print(content)
        except Exception as e:
            # æ¢å¤stdout
            sys.stdout = old_stdout
            logger.error(f"åˆ†æž{monitor_type}æ—¶å‡ºé”™: {e}")
            raise

    return wrapper


class EBPFAnalyzer:
    """eBPFæ•°æ®åˆ†æžå™¨ - é€‚é…æ–°çš„èšåˆç»Ÿè®¡æ•°æ®æ ¼å¼"""

    def __init__(self, daily_data_dir="./daily_data", reports_dir="./reports", hostname=None):
        self.hostname = hostname or socket.gethostname()
        self.daily_data_dir = os.path.join(daily_data_dir, self.hostname)
        self.reports_dir = os.path.join(reports_dir, self.hostname)
        self.base_reports_dir = reports_dir  # ä¿å­˜åŸºç¡€reportsç›®å½•ï¼Œç”¨äºŽå¯¹æ¯”åŠŸèƒ½
        # æ›´æ–°ç›‘æŽ§å™¨ç±»åž‹åˆ—è¡¨
        self.monitor_types = ['exec', 'syscall', 'bio', 'interrupt', 'func', 'open', 'page_fault']

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(self.daily_data_dir):
            os.makedirs(self.daily_data_dir)
        if not os.path.exists(self.reports_dir):
            os.makedirs(self.reports_dir)

    def load_daily_data(self, date_str: str, monitor_type: str) -> Optional[pd.DataFrame]:
        """
        åŠ è½½æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYYMMDD
            monitor_type: ç›‘æŽ§å™¨ç±»åž‹
            
        Returns:
            DataFrameæˆ–None
        """
        # ä»Ždaily_dataç›®å½•åŠ è½½
        daily_file = os.path.join(self.daily_data_dir, f"{monitor_type}_{date_str}.csv")
        if os.path.exists(daily_file):
            logger.info(f"åŠ è½½æ•°æ®: {daily_file}")
            df = safe_read_csv(daily_file)
            if not df.empty:
                return self.clean_loaded_data(df, monitor_type)

        logger.warning(f"æœªæ‰¾åˆ°{monitor_type}åœ¨{date_str}çš„æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œpreprocess_data.shé¢„å¤„ç†æ•°æ®")
        return None

    def clean_loaded_data(self, df: pd.DataFrame, monitor_type: str) -> pd.DataFrame:
        """
        æ¸…ç†åŠ è½½çš„æ•°æ®ï¼Œå¤„ç†æ ¼å¼é—®é¢˜
        
        Args:
            df: åŽŸå§‹DataFrame
            monitor_type: ç›‘æŽ§å™¨ç±»åž‹
            
        Returns:
            æ¸…ç†åŽçš„DataFrame
        """
        if df.empty:
            return df

        original_count = len(df)

        # 1. ç§»é™¤å®Œå…¨ç©ºçš„è¡Œ
        df = df.dropna(how='all')

        # 2. å¤„ç†timestampåˆ—
        if 'timestamp' in df.columns:
            df = df.dropna(subset=['timestamp'])
            df['timestamp'] = pd.to_numeric(df['timestamp'], errors='coerce')
            df = df.dropna(subset=['timestamp'])

        # 3. å¤„ç†time_stråˆ—ï¼ˆæ–°æ ¼å¼éƒ½æœ‰è¿™ä¸ªå­—æ®µï¼‰
        if 'time_str' in df.columns:
            df['time_str'] = df['time_str'].astype(str).str.strip()

        # 4. å¤„ç†commåˆ—ï¼ˆæ‰€æœ‰ç›‘æŽ§å™¨éƒ½æœ‰ï¼‰
        if 'comm' in df.columns:
            df['comm'] = df['comm'].astype(str).str.strip()

        # 5. æ ¹æ®ç›‘æŽ§å™¨ç±»åž‹å¤„ç†ç‰¹å®šå­—æ®µ
        df = self._clean_monitor_specific_fields(df, monitor_type)

        cleaned_count = len(df)
        if original_count != cleaned_count:
            logger.info(f"{monitor_type} æ•°æ®æ¸…ç†: {original_count} -> {cleaned_count} è¡Œ")

        return df

    def _clean_monitor_specific_fields(self, df: pd.DataFrame, monitor_type: str) -> pd.DataFrame:
        """å¤„ç†ç‰¹å®šç›‘æŽ§å™¨çš„å­—æ®µ"""

        # é€šç”¨æ•°å€¼å­—æ®µ
        common_numeric = ['count', 'errors', 'error_count']
        for col in common_numeric:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

        # é€šç”¨æµ®ç‚¹å­—æ®µ
        common_float = ['error_rate', 'avg_lat_us', 'min_lat_us', 'max_lat_us', 'avg_latency_us', 'min_latency_us',
                        'max_latency_us']
        for col in common_float:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)

        # ç‰¹å®šç›‘æŽ§å™¨çš„å­—æ®µå¤„ç†
        if monitor_type == 'exec':
            if 'uid' in df.columns:
                df['uid'] = pd.to_numeric(df['uid'], errors='coerce').fillna(0).astype(int)
            if 'pid' in df.columns:
                df['pid'] = pd.to_numeric(df['pid'], errors='coerce').fillna(0).astype(int)
            # ç¡®ä¿filenameæ˜¯å­—ç¬¦ä¸²ç±»åž‹
            if 'filename' in df.columns:
                df['filename'] = df['filename'].astype(str).str.strip()

        elif monitor_type == 'bio':
            numeric_cols = ['io_type', 'total_bytes', 'size_mb', 'throughput_mbps']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)

        elif monitor_type == 'syscall':
            if 'syscall_nr' in df.columns:
                df['syscall_nr'] = pd.to_numeric(df['syscall_nr'], errors='coerce').fillna(0).astype(int)
            # ç¡®ä¿syscall_nameæ˜¯å­—ç¬¦ä¸²ç±»åž‹
            if 'syscall_name' in df.columns:
                df['syscall_name'] = df['syscall_name'].astype(str).str.strip()
            if 'category' in df.columns:
                df['category'] = df['category'].astype(str).str.strip()

        elif monitor_type == 'open':
            # ç¡®ä¿filenameå’Œoperationæ˜¯å­—ç¬¦ä¸²ç±»åž‹
            if 'filename' in df.columns:
                df['filename'] = df['filename'].astype(str).str.strip()
            if 'operation' in df.columns:
                df['operation'] = df['operation'].astype(str).str.strip()

        elif monitor_type == 'func':
            # ç¡®ä¿func_nameæ˜¯å­—ç¬¦ä¸²ç±»åž‹
            if 'func_name' in df.columns:
                df['func_name'] = df['func_name'].astype(str).str.strip()

        elif monitor_type in ['interrupt', 'page_fault']:
            if 'cpu' in df.columns:
                df['cpu'] = pd.to_numeric(df['cpu'], errors='coerce').fillna(0).astype(int)
            if 'fault_type' in df.columns:
                df['fault_type'] = pd.to_numeric(df['fault_type'], errors='coerce').fillna(0).astype(int)
            if 'irq_type' in df.columns:
                df['irq_type'] = pd.to_numeric(df['irq_type'], errors='coerce').fillna(0).astype(int)
            # ç¡®ä¿ç±»åž‹å­—ç¬¦ä¸²å­—æ®µæ˜¯å­—ç¬¦ä¸²ç±»åž‹
            if 'fault_type_str' in df.columns:
                df['fault_type_str'] = df['fault_type_str'].astype(str).str.strip()
            if 'irq_type_str' in df.columns:
                df['irq_type_str'] = df['irq_type_str'].astype(str).str.strip()
            if 'numa_node' in df.columns:
                df['numa_node'] = pd.to_numeric(df['numa_node'], errors='coerce').fillna(0).astype(int)

        elif monitor_type == 'vfs':
            if 'bytes_mb' in df.columns:
                df['bytes_mb'] = pd.to_numeric(df['bytes_mb'], errors='coerce').fillna(0.0)

        elif monitor_type == 'context_switch':
            switch_cols = ['switch_in', 'switch_out', 'total_switches', 'voluntary', 'involuntary', 'voluntary_rate']
            for col in switch_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

        # ç¡®ä¿bioçš„io_type_stræ˜¯å­—ç¬¦ä¸²ç±»åž‹
        if monitor_type == 'bio' and 'io_type_str' in df.columns:
            df['io_type_str'] = df['io_type_str'].astype(str).str.strip()

        return df

    def _save_report(self, monitor_type: str, date_str: str, content: str):
        """ä¿å­˜åˆ†æžæŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report_file = os.path.join(self.reports_dir, f"{monitor_type}_{date_str}.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(content)
        logger.info(f"åˆ†æžæŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    # ==================== EXEC åˆ†æž ====================
    @capture_output_to_file
    def analyze_exec(self, date_str: str):
        """åˆ†æžEXECæ•°æ®"""
        df = self.load_daily_data(date_str, 'exec')
        if df is None or df.empty:
            return

        print(f"\n{'=' * 100}")
        print(f"EXEC ç›‘æŽ§æ•°æ®æ·±åº¦åˆ†æž - {date_str}")
        print(f"{'=' * 100}\n")

        # åŸºæœ¬ç»Ÿè®¡
        total_execs = len(df)
        unique_files = df['filename'].nunique() if 'filename' in df.columns else 0
        unique_comms = df['comm'].nunique() if 'comm' in df.columns else 0

        print(f"ã€æ¦‚è§ˆç»Ÿè®¡ã€‘")
        print(f"  æ€»æ‰§è¡Œæ¬¡æ•°: {total_execs:,}")
        print(f"  å”¯ä¸€å¯æ‰§è¡Œæ–‡ä»¶æ•°: {unique_files:,}")
        print(f"  å”¯ä¸€è¿›ç¨‹åæ•°: {unique_comms:,}")
        print(f"  å¹³å‡æ¯ä¸ªæ–‡ä»¶æ‰§è¡Œæ¬¡æ•°: {total_execs / unique_files:.2f}" if unique_files > 0 else "")

        # å®Œæ•´æ–‡ä»¶æ‰§è¡ŒæŽ’å
        if 'filename' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€å¯æ‰§è¡Œæ–‡ä»¶å®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            file_counts = df['filename'].value_counts()
            cumulative_pct = 0
            for i, (filename, count) in enumerate(file_counts.items(), 1):
                pct = (count / total_execs) * 100
                cumulative_pct += pct
                print(f"  {i:3d}. {filename:60s} {count:8d}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%]")

        # å®Œæ•´è¿›ç¨‹æŽ’å
        if 'comm' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹å®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            comm_counts = df['comm'].value_counts()
            cumulative_pct = 0
            for i, (comm, count) in enumerate(comm_counts.items(), 1):
                pct = (count / total_execs) * 100
                cumulative_pct += pct
                print(f"  {i:3d}. {comm:30s} {count:8d}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%]")

        # ç”¨æˆ·ç»´åº¦åˆ†æž
        if 'uid' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€ç”¨æˆ·ç»´åº¦åˆ†æžã€‘")
            print(f"{'=' * 100}")
            uid_stats = df['uid'].value_counts()
            for uid, count in uid_stats.items():
                pct = (count / total_execs) * 100
                user_type = "root" if uid == 0 else f"uid={uid}"
                print(f"  {user_type:15s} {count:8d}æ¬¡ ({pct:6.2f}%)")

                # æ˜¾ç¤ºè¯¥ç”¨æˆ·æ‰§è¡Œçš„ä¸»è¦ç¨‹åº
                user_df = df[df['uid'] == uid]
                if 'filename' in user_df.columns:
                    top_files = user_df['filename'].value_counts().head(5)
                    for j, (filename, fcount) in enumerate(top_files.items(), 1):
                        fpct = (fcount / count) * 100
                        print(f"      {j}. {filename:50s} {fcount:6d}æ¬¡ ({fpct:5.2f}%)")

        # è¿›ç¨‹-æ–‡ä»¶å…³è”åˆ†æž
        if 'comm' in df.columns and 'filename' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹-æ–‡ä»¶å…³è”åˆ†æžã€‘")
            print(f"{'=' * 100}")
            # æ‰¾å‡ºæ¯ä¸ªè¿›ç¨‹æœ€å¸¸æ‰§è¡Œçš„æ–‡ä»¶
            for comm in df['comm'].unique()[:20]:  # åªåˆ†æžå‰20ä¸ªè¿›ç¨‹
                comm_df = df[df['comm'] == comm]
                comm_total = len(comm_df)
                print(f"\nè¿›ç¨‹: {comm} (æ€»æ‰§è¡Œ: {comm_total:,}æ¬¡)")
                file_dist = comm_df['filename'].value_counts().head(10)
                for i, (filename, count) in enumerate(file_dist.items(), 1):
                    pct = (count / comm_total) * 100
                    print(f"  {i:2d}. {filename:60s} {count:6d}æ¬¡ ({pct:5.2f}%)")

        # æ‰§è¡Œé¢‘çŽ‡åˆ†æž
        if 'filename' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€æ‰§è¡Œé¢‘çŽ‡åˆ†å¸ƒã€‘")
            print(f"{'=' * 100}")
            file_counts = df['filename'].value_counts()

            # æŒ‰æ‰§è¡Œæ¬¡æ•°åˆ†æ®µç»Ÿè®¡
            ranges = [
                (1, 1, "ä»…æ‰§è¡Œ1æ¬¡"),
                (2, 5, "æ‰§è¡Œ2-5æ¬¡"),
                (6, 10, "æ‰§è¡Œ6-10æ¬¡"),
                (11, 50, "æ‰§è¡Œ11-50æ¬¡"),
                (51, 100, "æ‰§è¡Œ51-100æ¬¡"),
                (101, 500, "æ‰§è¡Œ101-500æ¬¡"),
                (501, float('inf'), "æ‰§è¡Œ500æ¬¡ä»¥ä¸Š")
            ]

            for min_count, max_count, label in ranges:
                if max_count == float('inf'):
                    files_in_range = file_counts[file_counts >= min_count]
                else:
                    files_in_range = file_counts[(file_counts >= min_count) & (file_counts <= max_count)]

                file_num = len(files_in_range)
                exec_num = files_in_range.sum()
                file_pct = (file_num / unique_files * 100) if unique_files > 0 else 0
                exec_pct = (exec_num / total_execs * 100) if total_execs > 0 else 0

                print(
                    f"  {label:20s} æ–‡ä»¶æ•°: {file_num:5d} ({file_pct:5.2f}%)  æ‰§è¡Œæ¬¡æ•°: {exec_num:8d} ({exec_pct:6.2f}%)")

    # ==================== BIO åˆ†æž ====================
    @capture_output_to_file
    def analyze_bio(self, date_str: str):
        """åˆ†æžBIOæ•°æ®ï¼ˆå—I/Oï¼‰"""
        df = self.load_daily_data(date_str, 'bio')
        if df is None or df.empty:
            return

        print(f"\n{'=' * 100}")
        print(f"BIO (å—I/O) ç›‘æŽ§æ•°æ®æ·±åº¦åˆ†æž - {date_str}")
        print(f"{'=' * 100}\n")

        # åŸºæœ¬ç»Ÿè®¡
        total_ops = df['count'].sum() if 'count' in df.columns else len(df)
        total_bytes = df['total_bytes'].sum() if 'total_bytes' in df.columns else 0
        total_mb = total_bytes / (1024 * 1024)
        total_gb = total_mb / 1024
        unique_procs = df['comm'].nunique() if 'comm' in df.columns else 0

        print(f"ã€æ¦‚è§ˆç»Ÿè®¡ã€‘")
        print(f"  æ€»I/Oæ“ä½œæ•°: {total_ops:,}")
        print(f"  æ€»æ•°æ®é‡: {total_gb:,.2f} GB ({total_mb:,.2f} MB)")
        print(f"  å¹³å‡æ¯æ¬¡I/Oå¤§å°: {total_bytes / total_ops / 1024:.2f} KB" if total_ops > 0 else "")
        print(f"  å”¯ä¸€è¿›ç¨‹æ•°: {unique_procs}")

        # I/Oç±»åž‹å®Œæ•´åˆ†æž
        if 'io_type_str' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€I/Oç±»åž‹å®Œæ•´åˆ†æžã€‘")
            print(f"{'=' * 100}")
            io_type_stats = df.groupby('io_type_str').agg({
                'count': 'sum',
                'total_bytes': 'sum',
                'avg_latency_us': 'mean',
                'min_latency_us': 'min',
                'max_latency_us': 'max'
            }).sort_values('count', ascending=False)

            for io_type, row in io_type_stats.iterrows():
                count = row['count']
                bytes_mb = row['total_bytes'] / (1024 * 1024)
                bytes_gb = bytes_mb / 1024
                avg_lat = row['avg_latency_us']
                min_lat = row['min_latency_us']
                max_lat = row['max_latency_us']
                ops_pct = (count / total_ops) * 100 if total_ops > 0 else 0
                bytes_pct = (row['total_bytes'] / total_bytes * 100) if total_bytes > 0 else 0

                print(f"\n{io_type}:")
                print(f"  æ“ä½œæ¬¡æ•°: {count:12,.0f} ({ops_pct:6.2f}%)")
                print(f"  æ•°æ®é‡:   {bytes_gb:12,.2f} GB ({bytes_mb:,.2f} MB, {bytes_pct:6.2f}%)")
                print(f"  å¹³å‡å»¶è¿Ÿ: {avg_lat:12,.2f} Î¼s")
                print(f"  å»¶è¿ŸèŒƒå›´: {min_lat:12,.2f} - {max_lat:12,.2f} Î¼s")
                print(f"  å¹³å‡å¤§å°: {row['total_bytes'] / count / 1024:12,.2f} KB/æ¬¡" if count > 0 else "")

        # è¿›ç¨‹å®Œæ•´æŽ’å
        if 'comm' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹I/Oå®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            proc_stats = df.groupby('comm').agg({
                'count': 'sum',
                'total_bytes': 'sum',
                'avg_latency_us': 'mean'
            }).sort_values('count', ascending=False)

            cumulative_ops_pct = 0
            cumulative_bytes_pct = 0
            for i, (comm, row) in enumerate(proc_stats.iterrows(), 1):
                count = row['count']
                bytes_mb = row['total_bytes'] / (1024 * 1024)
                avg_lat = row['avg_latency_us']
                ops_pct = (count / total_ops) * 100 if total_ops > 0 else 0
                bytes_pct = (row['total_bytes'] / total_bytes * 100) if total_bytes > 0 else 0
                cumulative_ops_pct += ops_pct
                cumulative_bytes_pct += bytes_pct

                print(
                    f"  {i:3d}. {comm:30s} {count:10,.0f}æ¬¡ ({ops_pct:5.2f}%) | {bytes_mb:10,.2f} MB ({bytes_pct:5.2f}%) | å»¶è¿Ÿ: {avg_lat:7,.2f}Î¼s")
                print(f"        [ç´¯è®¡æ“ä½œ: {cumulative_ops_pct:6.2f}%  ç´¯è®¡æ•°æ®: {cumulative_bytes_pct:6.2f}%]")

        # è¿›ç¨‹-I/Oç±»åž‹å…³è”åˆ†æž
        if 'comm' in df.columns and 'io_type_str' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹-I/Oç±»åž‹å…³è”åˆ†æžã€‘(Top 20è¿›ç¨‹)")
            print(f"{'=' * 100}")

            top_procs = df.groupby('comm')['count'].sum().nlargest(20).index
            for comm in top_procs:
                comm_df = df[df['comm'] == comm]
                comm_total = comm_df['count'].sum()
                comm_bytes = comm_df['total_bytes'].sum()

                print(f"\nè¿›ç¨‹: {comm} (æ€»æ“ä½œ: {comm_total:,}æ¬¡, æ€»æ•°æ®: {comm_bytes / 1024 / 1024:,.2f} MB)")

                io_dist = comm_df.groupby('io_type_str').agg({
                    'count': 'sum',
                    'total_bytes': 'sum',
                    'avg_latency_us': 'mean'
                }).sort_values('count', ascending=False)

                for io_type, row in io_dist.iterrows():
                    count = row['count']
                    bytes_mb = row['total_bytes'] / (1024 * 1024)
                    avg_lat = row['avg_latency_us']
                    ops_pct = (count / comm_total) * 100
                    bytes_pct = (row['total_bytes'] / comm_bytes * 100) if comm_bytes > 0 else 0
                    print(
                        f"  {io_type:15s} {count:10,}æ¬¡ ({ops_pct:5.2f}%) | {bytes_mb:8,.2f} MB ({bytes_pct:5.2f}%) | {avg_lat:7,.2f}Î¼s")

        # I/Oå¤§å°åˆ†å¸ƒ
        if 'total_bytes' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€I/Oå¤§å°åˆ†å¸ƒã€‘")
            print(f"{'=' * 100}")

            # è®¡ç®—æ¯æ¬¡æ“ä½œçš„å¹³å‡å¤§å°
            df_copy = df.copy()
            df_copy['avg_size_kb'] = df_copy['total_bytes'] / df_copy['count'] / 1024

            ranges = [
                (0, 4, "0-4 KB (å°I/O)"),
                (4, 64, "4-64 KB (ä¸­å°I/O)"),
                (64, 256, "64-256 KB (ä¸­ç­‰I/O)"),
                (256, 1024, "256 KB-1 MB (å¤§I/O)"),
                (1024, float('inf'), "1 MBä»¥ä¸Š (è¶…å¤§I/O)")
            ]

            for min_size, max_size, label in ranges:
                if max_size == float('inf'):
                    range_df = df_copy[df_copy['avg_size_kb'] >= min_size]
                else:
                    range_df = df_copy[(df_copy['avg_size_kb'] >= min_size) & (df_copy['avg_size_kb'] < max_size)]

                if not range_df.empty:
                    ops_count = range_df['count'].sum()
                    data_bytes = range_df['total_bytes'].sum()
                    ops_pct = (ops_count / total_ops * 100) if total_ops > 0 else 0
                    data_pct = (data_bytes / total_bytes * 100) if total_bytes > 0 else 0

                    print(
                        f"  {label:25s} æ“ä½œ: {ops_count:10,.0f} ({ops_pct:5.2f}%)  æ•°æ®: {data_bytes / 1024 / 1024:10,.2f} MB ({data_pct:5.2f}%)")

        # å»¶è¿Ÿåˆ†æž
        if 'avg_latency_us' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€å»¶è¿Ÿè¯¦ç»†åˆ†æžã€‘")
            print(f"{'=' * 100}")

            overall_avg = (df['avg_latency_us'] * df['count']).sum() / df['count'].sum() if 'count' in df.columns else \
                df['avg_latency_us'].mean()
            overall_min = df['min_latency_us'].min() if 'min_latency_us' in df.columns else 0
            overall_max = df['max_latency_us'].max() if 'max_latency_us' in df.columns else 0

            print(f"  æ•´ä½“å¹³å‡å»¶è¿Ÿ: {overall_avg:,.2f} Î¼s")
            print(f"  æœ€å°å»¶è¿Ÿ: {overall_min:,.2f} Î¼s")
            print(f"  æœ€å¤§å»¶è¿Ÿ: {overall_max:,.2f} Î¼s")

            # é«˜å»¶è¿Ÿè¿›ç¨‹å®Œæ•´æŽ’å
            if 'comm' in df.columns:
                print(f"\nè¿›ç¨‹å»¶è¿Ÿå®Œæ•´æŽ’å:")
                lat_procs = df.groupby('comm').agg({
                    'avg_latency_us': 'mean',
                    'count': 'sum'
                }).sort_values('avg_latency_us', ascending=False)

                for i, (comm, row) in enumerate(lat_procs.iterrows(), 1):
                    avg_lat = row['avg_latency_us']
                    count = row['count']
                    flag = " âš ï¸ " if avg_lat > overall_avg * 2 else "    "
                    print(f"  {i:3d}. {comm:30s} å¹³å‡å»¶è¿Ÿ: {avg_lat:10,.2f} Î¼s (æ“ä½œæ•°: {count:8,.0f}){flag}")

        # åžåé‡ç»Ÿè®¡
        if 'throughput_mbps' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€åžåé‡ç»Ÿè®¡ã€‘")
            print(f"{'=' * 100}")

            avg_throughput = df['throughput_mbps'].mean()
            max_throughput = df['throughput_mbps'].max()
            min_throughput = df['throughput_mbps'].min()

            print(f"  å¹³å‡åžåé‡: {avg_throughput:,.2f} MB/s")
            print(f"  æœ€å¤§åžåé‡: {max_throughput:,.2f} MB/s")
            print(f"  æœ€å°åžåé‡: {min_throughput:,.2f} MB/s")

            # æŒ‰è¿›ç¨‹çš„åžåé‡æŽ’å
            if 'comm' in df.columns:
                print(f"\nè¿›ç¨‹åžåé‡æŽ’å:")
                throughput_procs = df.groupby('comm')['throughput_mbps'].mean().sort_values(ascending=False)
                for i, (comm, tput) in enumerate(throughput_procs.items(), 1):
                    print(f"  {i:3d}. {comm:30s} {tput:10,.2f} MB/s")

    # ==================== FUNC åˆ†æž ====================
    @capture_output_to_file
    def analyze_func(self, date_str: str):
        """åˆ†æžFUNCæ•°æ®ï¼ˆVFSå‡½æ•°è°ƒç”¨ï¼‰"""
        df = self.load_daily_data(date_str, 'func')
        if df is None or df.empty:
            return

        print(f"\n{'=' * 100}")
        print(f"FUNC (VFSå‡½æ•°) ç›‘æŽ§æ•°æ®æ·±åº¦åˆ†æž - {date_str}")
        print(f"{'=' * 100}\n")

        # åŸºæœ¬ç»Ÿè®¡
        total_calls = df['count'].sum() if 'count' in df.columns else len(df)
        unique_funcs = df['func_name'].nunique() if 'func_name' in df.columns else 0
        unique_procs = df['comm'].nunique() if 'comm' in df.columns else 0

        print(f"ã€æ¦‚è§ˆç»Ÿè®¡ã€‘")
        print(f"  æ€»å‡½æ•°è°ƒç”¨æ¬¡æ•°: {total_calls:,}")
        print(f"  å”¯ä¸€å‡½æ•°æ•°: {unique_funcs}")
        print(f"  å”¯ä¸€è¿›ç¨‹æ•°: {unique_procs}")
        print(f"  å¹³å‡æ¯ä¸ªå‡½æ•°è°ƒç”¨æ¬¡æ•°: {total_calls / unique_funcs:,.2f}" if unique_funcs > 0 else "")
        print(f"  å¹³å‡æ¯ä¸ªè¿›ç¨‹è°ƒç”¨æ¬¡æ•°: {total_calls / unique_procs:,.2f}" if unique_procs > 0 else "")

        # VFSå‡½æ•°å®Œæ•´æŽ’å
        if 'func_name' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€VFSå‡½æ•°å®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            func_stats = df.groupby('func_name')['count'].sum().sort_values(ascending=False)

            cumulative_pct = 0
            for i, (func, count) in enumerate(func_stats.items(), 1):
                pct = (count / total_calls) * 100 if total_calls > 0 else 0
                cumulative_pct += pct
                print(f"  {i:3d}. {func:35s} {count:12,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%]")

        # è¿›ç¨‹å®Œæ•´æŽ’å
        if 'comm' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹VFSè°ƒç”¨å®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            proc_stats = df.groupby('comm')['count'].sum().sort_values(ascending=False)

            cumulative_pct = 0
            for i, (comm, count) in enumerate(proc_stats.items(), 1):
                pct = (count / total_calls) * 100 if total_calls > 0 else 0
                cumulative_pct += pct
                print(f"  {i:3d}. {comm:35s} {count:12,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%]")

        # è¿›ç¨‹-å‡½æ•°å…³è”åˆ†æž
        if 'comm' in df.columns and 'func_name' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹-å‡½æ•°å…³è”åˆ†æžã€‘(Top 20è¿›ç¨‹)")
            print(f"{'=' * 100}")

            top_procs = df.groupby('comm')['count'].sum().nlargest(20).index
            for comm in top_procs:
                comm_df = df[df['comm'] == comm]
                comm_total = comm_df['count'].sum()

                print(f"\nè¿›ç¨‹: {comm} (æ€»è°ƒç”¨: {comm_total:,}æ¬¡)")

                func_dist = comm_df.groupby('func_name')['count'].sum().sort_values(ascending=False)
                for i, (func, count) in enumerate(func_dist.items(), 1):
                    pct = (count / comm_total) * 100
                    print(f"  {i:3d}. {func:35s} {count:10,}æ¬¡ ({pct:5.2f}%)")

        # å‡½æ•°è°ƒç”¨é¢‘çŽ‡åˆ†å¸ƒ
        if 'func_name' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€å‡½æ•°è°ƒç”¨é¢‘çŽ‡åˆ†å¸ƒã€‘")
            print(f"{'=' * 100}")

            func_counts = df.groupby('func_name')['count'].sum()

            ranges = [
                (1, 100, "1-100æ¬¡"),
                (101, 1000, "101-1,000æ¬¡"),
                (1001, 10000, "1,001-10,000æ¬¡"),
                (10001, 100000, "10,001-100,000æ¬¡"),
                (100001, 1000000, "100,001-1,000,000æ¬¡"),
                (1000001, float('inf'), "1,000,000æ¬¡ä»¥ä¸Š")
            ]

            for min_count, max_count, label in ranges:
                if max_count == float('inf'):
                    funcs_in_range = func_counts[func_counts >= min_count]
                else:
                    funcs_in_range = func_counts[(func_counts >= min_count) & (func_counts <= max_count)]

                func_num = len(funcs_in_range)
                call_num = funcs_in_range.sum()
                func_pct = (func_num / unique_funcs * 100) if unique_funcs > 0 else 0
                call_pct = (call_num / total_calls * 100) if total_calls > 0 else 0

                print(
                    f"  {label:25s} å‡½æ•°æ•°: {func_num:4d} ({func_pct:5.2f}%)  è°ƒç”¨æ¬¡æ•°: {call_num:12,} ({call_pct:6.2f}%)")

        # å‡½æ•°-è¿›ç¨‹äº¤å‰ç»Ÿè®¡çŸ©é˜µ
        if 'comm' in df.columns and 'func_name' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€å‡½æ•°-è¿›ç¨‹è°ƒç”¨çŸ©é˜µã€‘(Top 10è¿›ç¨‹ Ã— æ‰€æœ‰å‡½æ•°)")
            print(f"{'=' * 100}")
            top_procs = df.groupby('comm')['count'].sum().nlargest(10).index
            pivot = df[df['comm'].isin(top_procs)].pivot_table(
                index='comm', columns='func_name', values='count', aggfunc='sum', fill_value=0
            )
            print(pivot.to_string())

    # ==================== OPEN åˆ†æž ====================
    @capture_output_to_file
    def analyze_open(self, date_str: str):
        """åˆ†æžOPENæ•°æ®"""
        df = self.load_daily_data(date_str, 'open')
        if df is None or df.empty:
            return

        print(f"\n{'=' * 100}")
        print(f"OPEN (æ–‡ä»¶æ‰“å¼€) ç›‘æŽ§æ•°æ®æ·±åº¦åˆ†æž - {date_str}")
        print(f"{'=' * 100}\n")

        # åŸºæœ¬ç»Ÿè®¡
        total_opens = df['count'].sum() if 'count' in df.columns else len(df)
        total_errors = df['errors'].sum() if 'errors' in df.columns else 0
        error_rate = (total_errors / total_opens * 100) if total_opens > 0 else 0
        unique_files = df['filename'].nunique() if 'filename' in df.columns else 0
        unique_procs = df['comm'].nunique() if 'comm' in df.columns else 0

        print(f"ã€æ¦‚è§ˆç»Ÿè®¡ã€‘")
        print(f"  æ€»æ‰“å¼€æ¬¡æ•°: {total_opens:,}")
        print(f"  æ€»é”™è¯¯æ¬¡æ•°: {total_errors:,}")
        print(f"  æ•´ä½“é”™è¯¯çŽ‡: {error_rate:.4f}%")
        print(f"  å”¯ä¸€æ–‡ä»¶æ•°: {unique_files:,}")
        print(f"  å”¯ä¸€è¿›ç¨‹æ•°: {unique_procs}")
        print(f"  å¹³å‡æ¯ä¸ªæ–‡ä»¶è¢«æ‰“å¼€æ¬¡æ•°: {total_opens / unique_files:.2f}" if unique_files > 0 else "")

        # æ“ä½œç±»åž‹åˆ†æž
        if 'operation' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€æ“ä½œç±»åž‹åˆ†æžã€‘")
            print(f"{'=' * 100}")
            op_stats = df.groupby('operation').agg({
                'count': 'sum',
                'errors': 'sum'
            }).sort_values('count', ascending=False)

            for op, row in op_stats.iterrows():
                count = row['count']
                errors = row['errors']
                err_rate = (errors / count * 100) if count > 0 else 0
                pct = (count / total_opens) * 100 if total_opens > 0 else 0
                err_flag = " âš ï¸ " if err_rate > 1.0 else "    "
                print(f"  {op:15s} {count:10,}æ¬¡ ({pct:6.2f}%) | é”™è¯¯: {errors:8,}æ¬¡ ({err_rate:6.2f}%){err_flag}")

        # æ–‡ä»¶å®Œæ•´æŽ’å
        if 'filename' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€æ–‡ä»¶æ‰“å¼€æŽ’åã€‘ (Top 30)")
            print(f"{'=' * 100}")
            file_stats = df.groupby('filename').agg({
                'count': 'sum',
                'errors': 'sum'
            }).sort_values('count', ascending=False).head(30)

            cumulative_pct = 0
            for i, (filename, row) in enumerate(file_stats.iterrows(), 1):
                count = row['count']
                errors = row['errors']
                err_rate = (errors / count * 100) if count > 0 else 0
                pct = (count / total_opens) * 100 if total_opens > 0 else 0
                cumulative_pct += pct

                err_flag = " âš ï¸ " if err_rate > 5.0 else "    "
                print(
                    f"  {i:4d}. {filename:70s} {count:8,}æ¬¡ ({pct:5.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%] | é”™è¯¯: {errors:6,} ({err_rate:5.2f}%){err_flag}")

        # è¿›ç¨‹å®Œæ•´æŽ’å
        if 'comm' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹æ–‡ä»¶æ‰“å¼€æŽ’åã€‘ (Top 30)")
            print(f"{'=' * 100}")
            proc_stats = df.groupby('comm').agg({
                'count': 'sum',
                'errors': 'sum'
            }).sort_values('count', ascending=False).head(30)

            cumulative_pct = 0
            for i, (comm, row) in enumerate(proc_stats.iterrows(), 1):
                count = row['count']
                errors = row['errors']
                err_rate = (errors / count * 100) if count > 0 else 0
                pct = (count / total_opens) * 100 if total_opens > 0 else 0
                cumulative_pct += pct

                err_flag = " âš ï¸ " if err_rate > 1.0 else "    "
                print(
                    f"  {i:3d}. {comm:30s} {count:10,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%] | é”™è¯¯: {errors:8,}æ¬¡ ({err_rate:6.2f}%){err_flag}")

        # è¿›ç¨‹-æ–‡ä»¶å…³è”åˆ†æž
        if 'comm' in df.columns and 'filename' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹-æ–‡ä»¶å…³è”åˆ†æžã€‘(Top 20è¿›ç¨‹)")
            print(f"{'=' * 100}")

            top_procs = df.groupby('comm')['count'].sum().nlargest(20).index
            for comm in top_procs:
                comm_df = df[df['comm'] == comm]
                comm_total = comm_df['count'].sum()
                comm_errors = comm_df['errors'].sum()

                print(f"\nè¿›ç¨‹: {comm} (æ€»æ‰“å¼€: {comm_total:,}æ¬¡, é”™è¯¯: {comm_errors:,}æ¬¡)")

                file_dist = comm_df.groupby('filename').agg({
                    'count': 'sum',
                    'errors': 'sum'
                }).sort_values('count', ascending=False).head(15)

                for i, (filename, row) in enumerate(file_dist.iterrows(), 1):
                    count = row['count']
                    errors = row['errors']
                    pct = (count / comm_total) * 100
                    err_rate = (errors / count * 100) if count > 0 else 0
                    print(f"  {i:3d}. {filename:65s} {count:6,}æ¬¡ ({pct:5.2f}%) | é”™è¯¯: {errors:4,} ({err_rate:5.2f}%)")

        # é”™è¯¯è¯¦ç»†åˆ†æž
        if 'errors' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€é”™è¯¯è¯¦ç»†åˆ†æžã€‘")
            print(f"{'=' * 100}")

            error_df = df[df['errors'] > 0].copy()
            if not error_df.empty:
                # æŒ‰filenameèšåˆé”™è¯¯æ•°æ®
                if 'filename' in error_df.columns:
                    file_error_stats = error_df.groupby('filename').agg({
                        'count': 'sum',
                        'errors': 'sum'
                    })
                    file_error_stats['err_rate'] = (file_error_stats['errors'] / file_error_stats['count'] * 100)

                    # é”™è¯¯çŽ‡æœ€é«˜çš„æ–‡ä»¶
                    print(f"\né”™è¯¯çŽ‡æœ€é«˜çš„æ–‡ä»¶ (Top 30):")
                    top_err_files = file_error_stats.sort_values(
                        by=['err_rate', 'errors'],
                        ascending=[False, False]
                    ).head(30)
                    for i, (filename, row) in enumerate(top_err_files.iterrows(), 1):
                        print(
                            f"  {i:2d}. {filename:65s} é”™è¯¯çŽ‡: {row['err_rate']:6.2f}% ({row['errors']:,}/{row['count']:,})")

                    # é”™è¯¯æ¬¡æ•°æœ€å¤šçš„æ–‡ä»¶
                    print(f"\né”™è¯¯æ¬¡æ•°æœ€å¤šçš„æ–‡ä»¶ (Top 30):")
                    top_err_counts = file_error_stats.nlargest(30, 'errors')
                    for i, (filename, row) in enumerate(top_err_counts.iterrows(), 1):
                        print(f"  {i:2d}. {filename:65s} é”™è¯¯: {row['errors']:6,}æ¬¡ (é”™è¯¯çŽ‡: {row['err_rate']:6.2f}%)")

                # é”™è¯¯æœ€å¤šçš„è¿›ç¨‹
                if 'comm' in error_df.columns:
                    print(f"\né”™è¯¯æœ€å¤šçš„è¿›ç¨‹ (Top 30):")
                    proc_errors = error_df.groupby('comm').agg({
                        'count': 'sum',
                        'errors': 'sum'
                    }).sort_values('errors', ascending=False).head(30)

                    for i, (comm, row) in enumerate(proc_errors.iterrows(), 1):
                        err_rate = (row['errors'] / row['count'] * 100) if row['count'] > 0 else 0
                        print(f"  {i:2d}. {comm:30s} é”™è¯¯: {row['errors']:8,}æ¬¡ (é”™è¯¯çŽ‡: {err_rate:6.2f}%)")

        # æ–‡ä»¶è®¿é—®é¢‘çŽ‡åˆ†å¸ƒ
        if 'filename' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€æ–‡ä»¶è®¿é—®é¢‘çŽ‡åˆ†å¸ƒã€‘")
            print(f"{'=' * 100}")

            file_counts = df.groupby('filename')['count'].sum()

            ranges = [
                (1, 1, "ä»…æ‰“å¼€1æ¬¡"),
                (2, 10, "æ‰“å¼€2-10æ¬¡"),
                (11, 100, "æ‰“å¼€11-100æ¬¡"),
                (101, 1000, "æ‰“å¼€101-1,000æ¬¡"),
                (1001, 10000, "æ‰“å¼€1,001-10,000æ¬¡"),
                (10001, float('inf'), "æ‰“å¼€10,000æ¬¡ä»¥ä¸Š")
            ]

            for min_count, max_count, label in ranges:
                if max_count == float('inf'):
                    files_in_range = file_counts[file_counts >= min_count]
                else:
                    files_in_range = file_counts[(file_counts >= min_count) & (file_counts <= max_count)]

                file_num = len(files_in_range)
                open_num = files_in_range.sum()
                file_pct = (file_num / unique_files * 100) if unique_files > 0 else 0
                open_pct = (open_num / total_opens * 100) if total_opens > 0 else 0

                print(
                    f"  {label:25s} æ–‡ä»¶æ•°: {file_num:6d} ({file_pct:5.2f}%)  æ‰“å¼€æ¬¡æ•°: {open_num:10,} ({open_pct:6.2f}%)")

    # ==================== SYSCALL åˆ†æž ====================
    @capture_output_to_file
    def analyze_syscall(self, date_str: str):
        """åˆ†æžSYSCALLæ•°æ®"""
        df = self.load_daily_data(date_str, 'syscall')
        if df is None or df.empty:
            return

        print(f"\n{'=' * 100}")
        print(f"SYSCALL (ç³»ç»Ÿè°ƒç”¨) ç›‘æŽ§æ•°æ®æ·±åº¦åˆ†æž - {date_str}")
        print(f"{'=' * 100}\n")

        # åŸºæœ¬ç»Ÿè®¡
        total_calls = df['count'].sum() if 'count' in df.columns else len(df)
        total_errors = df['error_count'].sum() if 'error_count' in df.columns else 0
        error_rate = (total_errors / total_calls * 100) if total_calls > 0 else 0
        unique_syscalls = df['syscall_name'].nunique() if 'syscall_name' in df.columns else 0
        unique_procs = df['comm'].nunique() if 'comm' in df.columns else 0

        print(f"ã€æ¦‚è§ˆç»Ÿè®¡ã€‘")
        print(f"  æ€»ç³»ç»Ÿè°ƒç”¨æ¬¡æ•°: {total_calls:,}")
        print(f"  æ€»é”™è¯¯æ¬¡æ•°: {total_errors:,}")
        print(f"  æ•´ä½“é”™è¯¯çŽ‡: {error_rate:.4f}%")
        print(f"  å”¯ä¸€ç³»ç»Ÿè°ƒç”¨æ•°: {unique_syscalls}")
        print(f"  å”¯ä¸€è¿›ç¨‹æ•°: {unique_procs}")

        # ç³»ç»Ÿè°ƒç”¨å®Œæ•´æŽ’å
        if 'syscall_name' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€ç³»ç»Ÿè°ƒç”¨å®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            syscall_stats = df.groupby('syscall_name').agg({
                'count': 'sum',
                'error_count': 'sum'
            }).sort_values('count', ascending=False)

            cumulative_pct = 0
            for i, (syscall, row) in enumerate(syscall_stats.iterrows(), 1):
                count = row['count']
                errors = row['error_count']
                err_rate = (errors / count * 100) if count > 0 else 0
                pct = (count / total_calls) * 100 if total_calls > 0 else 0
                cumulative_pct += pct

                # æ ‡è®°é«˜é”™è¯¯çŽ‡
                err_flag = " âš ï¸ " if err_rate > 1.0 else "    "
                print(
                    f"  {i:3d}. {syscall:25s} {count:12,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%] | é”™è¯¯: {errors:10,}æ¬¡ ({err_rate:6.2f}%){err_flag}")

        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        if 'category' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€ç³»ç»Ÿè°ƒç”¨ç±»åˆ«åˆ†æžã€‘")
            print(f"{'=' * 100}")
            cat_stats = df.groupby('category').agg({
                'count': 'sum',
                'error_count': 'sum'
            }).sort_values('count', ascending=False)

            for cat, row in cat_stats.iterrows():
                count = row['count']
                errors = row['error_count']
                err_rate = (errors / count * 100) if count > 0 else 0
                pct = (count / total_calls) * 100 if total_calls > 0 else 0
                print(f"  {cat:20s} {count:12,}æ¬¡ ({pct:6.2f}%) | é”™è¯¯: {errors:10,}æ¬¡ ({err_rate:6.2f}%)")

                # æ˜¾ç¤ºè¯¥ç±»åˆ«ä¸‹çš„ä¸»è¦ç³»ç»Ÿè°ƒç”¨
                cat_df = df[df['category'] == cat]
                cat_syscalls = cat_df.groupby('syscall_name')['count'].sum().sort_values(ascending=False).head(5)
                for j, (syscall, scount) in enumerate(cat_syscalls.items(), 1):
                    spct = (scount / count) * 100
                    print(f"      {j}. {syscall:20s} {scount:10,}æ¬¡ ({spct:5.2f}%)")

        # è¿›ç¨‹å®Œæ•´æŽ’å
        if 'comm' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹ç³»ç»Ÿè°ƒç”¨å®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            proc_stats = df.groupby('comm').agg({
                'count': 'sum',
                'error_count': 'sum'
            }).sort_values('count', ascending=False)

            cumulative_pct = 0
            for i, (comm, row) in enumerate(proc_stats.iterrows(), 1):
                count = row['count']
                errors = row['error_count']
                err_rate = (errors / count * 100) if count > 0 else 0
                pct = (count / total_calls) * 100 if total_calls > 0 else 0
                cumulative_pct += pct

                err_flag = " âš ï¸ " if err_rate > 1.0 else "    "
                print(
                    f"  {i:3d}. {comm:30s} {count:12,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%] | é”™è¯¯: {errors:10,}æ¬¡ ({err_rate:6.2f}%){err_flag}")

        # è¿›ç¨‹-ç³»ç»Ÿè°ƒç”¨å…³è”åˆ†æž
        if 'comm' in df.columns and 'syscall_name' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹-ç³»ç»Ÿè°ƒç”¨å…³è”åˆ†æžã€‘(Top 15è¿›ç¨‹)")
            print(f"{'=' * 100}")

            top_procs = df.groupby('comm')['count'].sum().nlargest(15).index
            for comm in top_procs:
                comm_df = df[df['comm'] == comm]
                comm_total = comm_df['count'].sum()
                print(f"\nè¿›ç¨‹: {comm} (æ€»è°ƒç”¨: {comm_total:,}æ¬¡)")

                syscall_dist = comm_df.groupby('syscall_name').agg({
                    'count': 'sum',
                    'error_count': 'sum'
                }).sort_values('count', ascending=False).head(10)

                for i, (syscall, row) in enumerate(syscall_dist.iterrows(), 1):
                    count = row['count']
                    errors = row['error_count']
                    pct = (count / comm_total) * 100
                    err_rate = (errors / count * 100) if count > 0 else 0
                    print(
                        f"  {i:2d}. {syscall:25s} {count:10,}æ¬¡ ({pct:5.2f}%) | é”™è¯¯: {errors:8,}æ¬¡ ({err_rate:5.2f}%)")

        # é”™è¯¯åˆ†æž
        if 'error_count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€é”™è¯¯è¯¦ç»†åˆ†æžã€‘")
            print(f"{'=' * 100}")

            # é”™è¯¯çŽ‡æœ€é«˜çš„ç³»ç»Ÿè°ƒç”¨
            error_df = df[df['error_count'] > 0].copy()
            if not error_df.empty and 'syscall_name' in error_df.columns and 'count' in error_df.columns:
                # æŒ‰syscall_nameèšåˆé”™è¯¯æ•°æ®
                syscall_error_stats = error_df.groupby('syscall_name').agg({
                    'count': 'sum',
                    'error_count': 'sum'
                })
                syscall_error_stats['err_rate'] = (
                            syscall_error_stats['error_count'] / syscall_error_stats['count'] * 100)

                print(f"\né”™è¯¯çŽ‡æœ€é«˜çš„ç³»ç»Ÿè°ƒç”¨ (Top 20):")
                top_errors = syscall_error_stats.sort_values(
                    by=['err_rate', 'error_count'],
                    ascending=[False, False]
                ).head(20)
                for i, (syscall_name, row) in enumerate(top_errors.iterrows(), 1):
                    print(
                        f"  {i:2d}. {syscall_name:25s} é”™è¯¯çŽ‡: {row['err_rate']:6.2f}% ({row['error_count']:,}/{row['count']:,})")

                # é”™è¯¯æ¬¡æ•°æœ€å¤šçš„ç³»ç»Ÿè°ƒç”¨
                print(f"\né”™è¯¯æ¬¡æ•°æœ€å¤šçš„ç³»ç»Ÿè°ƒç”¨ (Top 20):")
                top_error_counts = syscall_error_stats.nlargest(20, 'error_count')
                for i, (syscall_name, row) in enumerate(top_error_counts.iterrows(), 1):
                    print(
                        f"  {i:2d}. {syscall_name:25s} é”™è¯¯: {row['error_count']:10,}æ¬¡ (é”™è¯¯çŽ‡: {row['err_rate']:6.2f}%)")

            # é”™è¯¯æœ€å¤šçš„è¿›ç¨‹
            if not error_df.empty and 'comm' in error_df.columns:
                print(f"\né”™è¯¯æœ€å¤šçš„è¿›ç¨‹ (Top 20):")
                proc_errors = error_df.groupby('comm').agg({
                    'count': 'sum',
                    'error_count': 'sum'
                }).sort_values('error_count', ascending=False).head(20)

                for i, (comm, row) in enumerate(proc_errors.iterrows(), 1):
                    err_rate = (row['error_count'] / row['count'] * 100) if row['count'] > 0 else 0
                    print(f"  {i:2d}. {comm:30s} é”™è¯¯: {row['error_count']:10,}æ¬¡ (é”™è¯¯çŽ‡: {err_rate:6.2f}%)")

        # è°ƒç”¨é¢‘çŽ‡åˆ†å¸ƒ
        if 'syscall_name' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€ç³»ç»Ÿè°ƒç”¨é¢‘çŽ‡åˆ†å¸ƒã€‘")
            print(f"{'=' * 100}")

            syscall_counts = df.groupby('syscall_name')['count'].sum()

            ranges = [
                (1, 100, "1-100æ¬¡"),
                (101, 1000, "101-1,000æ¬¡"),
                (1001, 10000, "1,001-10,000æ¬¡"),
                (10001, 100000, "10,001-100,000æ¬¡"),
                (100001, 1000000, "100,001-1,000,000æ¬¡"),
                (1000001, float('inf'), "1,000,000æ¬¡ä»¥ä¸Š")
            ]

            for min_count, max_count, label in ranges:
                if max_count == float('inf'):
                    syscalls_in_range = syscall_counts[syscall_counts >= min_count]
                else:
                    syscalls_in_range = syscall_counts[(syscall_counts >= min_count) & (syscall_counts <= max_count)]

                syscall_num = len(syscalls_in_range)
                call_num = syscalls_in_range.sum()
                syscall_pct = (syscall_num / unique_syscalls * 100) if unique_syscalls > 0 else 0
                call_pct = (call_num / total_calls * 100) if total_calls > 0 else 0

                print(
                    f"  {label:25s} ç³»ç»Ÿè°ƒç”¨æ•°: {syscall_num:4d} ({syscall_pct:5.2f}%)  è°ƒç”¨æ¬¡æ•°: {call_num:12,} ({call_pct:6.2f}%)")

    # ==================== INTERRUPT åˆ†æž ====================
    @capture_output_to_file
    def analyze_interrupt(self, date_str: str):
        """åˆ†æžINTERRUPTæ•°æ®"""
        df = self.load_daily_data(date_str, 'interrupt')
        if df is None or df.empty:
            return

        print(f"\n{'=' * 100}")
        print(f"INTERRUPT (ä¸­æ–­) ç›‘æŽ§æ•°æ®æ·±åº¦åˆ†æž - {date_str}")
        print(f"{'=' * 100}\n")

        # åŸºæœ¬ç»Ÿè®¡
        total_interrupts = df['count'].sum() if 'count' in df.columns else len(df)
        unique_types = df['irq_type_str'].nunique() if 'irq_type_str' in df.columns else 0
        unique_procs = df['comm'].nunique() if 'comm' in df.columns else 0
        unique_cpus = df['cpu'].nunique() if 'cpu' in df.columns else 0

        print(f"ã€æ¦‚è§ˆç»Ÿè®¡ã€‘")
        print(f"  æ€»ä¸­æ–­æ¬¡æ•°: {total_interrupts:,}")
        print(f"  ä¸­æ–­ç±»åž‹æ•°: {unique_types}")
        print(f"  æ¶‰åŠè¿›ç¨‹æ•°: {unique_procs}")
        print(f"  æ¶‰åŠCPUæ•°: {unique_cpus}")
        print(f"  å¹³å‡æ¯CPUä¸­æ–­æ•°: {total_interrupts / unique_cpus:,.2f}" if unique_cpus > 0 else "")

        # ä¸­æ–­ç±»åž‹å®Œæ•´åˆ†æž
        if 'irq_type_str' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€ä¸­æ–­ç±»åž‹å®Œæ•´åˆ†æžã€‘")
            print(f"{'=' * 100}")
            type_stats = df.groupby('irq_type_str')['count'].sum().sort_values(ascending=False)

            cumulative_pct = 0
            for i, (irq_type, count) in enumerate(type_stats.items(), 1):
                pct = (count / total_interrupts) * 100 if total_interrupts > 0 else 0
                cumulative_pct += pct
                print(f"  {i:3d}. {irq_type:30s} {count:12,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%]")

        # CPUè´Ÿè½½åˆ†æž
        if 'cpu' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€CPUä¸­æ–­è´Ÿè½½åˆ†æžã€‘")
            print(f"{'=' * 100}")
            cpu_stats = df.groupby('cpu')['count'].sum().sort_values(ascending=False)
            avg_per_cpu = total_interrupts / len(cpu_stats) if len(cpu_stats) > 0 else 0

            print(f"  å¹³å‡æ¯CPUä¸­æ–­æ•°: {avg_per_cpu:,.2f}")
            print(f"\nCPUä¸­æ–­åˆ†å¸ƒ:")

            for cpu, count in cpu_stats.items():
                pct = (count / total_interrupts) * 100 if total_interrupts > 0 else 0
                ratio = count / avg_per_cpu if avg_per_cpu > 0 else 0
                deviation = ((count - avg_per_cpu) / avg_per_cpu * 100) if avg_per_cpu > 0 else 0

                # è´Ÿè½½æ ‡è®°
                if ratio > 2.0:
                    indicator = "ðŸ”¥ðŸ”¥"
                elif ratio > 1.5:
                    indicator = "ðŸ”¥ "
                elif ratio < 0.5:
                    indicator = "â„ï¸ "
                else:
                    indicator = "   "

                print(
                    f"  {indicator} CPU {cpu:3d}: {count:12,}æ¬¡ ({pct:5.2f}%) | è´Ÿè½½æ¯”: {ratio:5.2f}x | åå·®: {deviation:+6.1f}%")

        # CPU-ä¸­æ–­ç±»åž‹å…³è”åˆ†æž
        if 'cpu' in df.columns and 'irq_type_str' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€CPU-ä¸­æ–­ç±»åž‹å…³è”åˆ†æžã€‘(Top 10 CPU)")
            print(f"{'=' * 100}")

            top_cpus = df.groupby('cpu')['count'].sum().nlargest(10).index
            for cpu in top_cpus:
                cpu_df = df[df['cpu'] == cpu]
                cpu_total = cpu_df['count'].sum()

                print(f"\nCPU {cpu} (æ€»ä¸­æ–­: {cpu_total:,}æ¬¡)")

                irq_dist = cpu_df.groupby('irq_type_str')['count'].sum().sort_values(ascending=False)
                for i, (irq_type, count) in enumerate(irq_dist.items(), 1):
                    pct = (count / cpu_total) * 100
                    print(f"  {i:2d}. {irq_type:30s} {count:10,}æ¬¡ ({pct:5.2f}%)")

        # è¿›ç¨‹å®Œæ•´æŽ’å
        if 'comm' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹ä¸­æ–­å®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            proc_stats = df.groupby('comm')['count'].sum().sort_values(ascending=False)

            cumulative_pct = 0
            for i, (comm, count) in enumerate(proc_stats.items(), 1):
                pct = (count / total_interrupts) * 100 if total_interrupts > 0 else 0
                cumulative_pct += pct
                print(f"  {i:3d}. {comm:35s} {count:12,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%]")

        # è¿›ç¨‹-ä¸­æ–­ç±»åž‹å…³è”åˆ†æž
        if 'comm' in df.columns and 'irq_type_str' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹-ä¸­æ–­ç±»åž‹å…³è”åˆ†æžã€‘(Top 15è¿›ç¨‹)")
            print(f"{'=' * 100}")

            top_procs = df.groupby('comm')['count'].sum().nlargest(15).index
            for comm in top_procs:
                comm_df = df[df['comm'] == comm]
                comm_total = comm_df['count'].sum()

                print(f"\nè¿›ç¨‹: {comm} (æ€»ä¸­æ–­: {comm_total:,}æ¬¡)")

                irq_dist = comm_df.groupby('irq_type_str')['count'].sum().sort_values(ascending=False)
                for i, (irq_type, count) in enumerate(irq_dist.items(), 1):
                    pct = (count / comm_total) * 100
                    print(f"  {i:2d}. {irq_type:30s} {count:10,}æ¬¡ ({pct:5.2f}%)")

        # ä¸­æ–­é¢‘çŽ‡åˆ†å¸ƒ
        if 'irq_type_str' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€ä¸­æ–­é¢‘çŽ‡åˆ†å¸ƒã€‘")
            print(f"{'=' * 100}")

            irq_counts = df.groupby('irq_type_str')['count'].sum()

            ranges = [
                (1, 1000, "1-1,000æ¬¡"),
                (1001, 10000, "1,001-10,000æ¬¡"),
                (10001, 100000, "10,001-100,000æ¬¡"),
                (100001, 1000000, "100,001-1,000,000æ¬¡"),
                (1000001, 10000000, "1,000,001-10,000,000æ¬¡"),
                (10000001, float('inf'), "10,000,000æ¬¡ä»¥ä¸Š")
            ]

            for min_count, max_count, label in ranges:
                if max_count == float('inf'):
                    irqs_in_range = irq_counts[irq_counts >= min_count]
                else:
                    irqs_in_range = irq_counts[(irq_counts >= min_count) & (irq_counts <= max_count)]

                irq_num = len(irqs_in_range)
                int_num = irqs_in_range.sum()
                irq_pct = (irq_num / unique_types * 100) if unique_types > 0 else 0
                int_pct = (int_num / total_interrupts * 100) if total_interrupts > 0 else 0

                print(
                    f"  {label:30s} ä¸­æ–­ç±»åž‹: {irq_num:3d} ({irq_pct:5.2f}%)  ä¸­æ–­æ¬¡æ•°: {int_num:12,} ({int_pct:6.2f}%)")

        # CPUè´Ÿè½½å‡è¡¡åˆ†æž
        if 'cpu' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€CPUè´Ÿè½½å‡è¡¡åˆ†æžã€‘")
            print(f"{'=' * 100}")

            cpu_counts = df.groupby('cpu')['count'].sum()
            max_load = cpu_counts.max()
            min_load = cpu_counts.min()
            avg_load = cpu_counts.mean()
            std_load = cpu_counts.std()

            print(f"  æœ€å¤§è´Ÿè½½CPU: {cpu_counts.idxmax()} ({max_load:,}æ¬¡)")
            print(f"  æœ€å°è´Ÿè½½CPU: {cpu_counts.idxmin()} ({min_load:,}æ¬¡)")
            print(f"  å¹³å‡è´Ÿè½½: {avg_load:,.2f}æ¬¡")
            print(f"  æ ‡å‡†å·®: {std_load:,.2f}")
            print(f"  è´Ÿè½½å·®å¼‚: {max_load - min_load:,}æ¬¡ ({(max_load - min_load) / avg_load * 100:.1f}%)")
            print(f"  è´Ÿè½½æ¯”: {max_load / min_load:.2f}x" if min_load > 0 else "")

            # è´Ÿè½½å‡è¡¡åº¦è¯„ä¼°
            balance_score = 1 - (std_load / avg_load) if avg_load > 0 else 0
            if balance_score > 0.9:
                balance_level = "ä¼˜ç§€ âœ“"
            elif balance_score > 0.7:
                balance_level = "è‰¯å¥½"
            elif balance_score > 0.5:
                balance_level = "ä¸€èˆ¬"
            else:
                balance_level = "è¾ƒå·® âš ï¸"

            print(f"\n  è´Ÿè½½å‡è¡¡åº¦: {balance_score * 100:.1f}% ({balance_level})")

    # ==================== PAGE_FAULT åˆ†æž ====================
    @capture_output_to_file
    def analyze_page_fault(self, date_str: str):
        """åˆ†æžPAGE_FAULTæ•°æ®"""
        df = self.load_daily_data(date_str, 'page_fault')
        if df is None or df.empty:
            return

        print(f"\n{'=' * 100}")
        print(f"PAGE_FAULT (é¡µé¢é”™è¯¯) ç›‘æŽ§æ•°æ®æ·±åº¦åˆ†æž - {date_str}")
        print(f"{'=' * 100}\n")

        # åŸºæœ¬ç»Ÿè®¡
        total_faults = df['count'].sum() if 'count' in df.columns else len(df)
        unique_types = df['fault_type_str'].nunique() if 'fault_type_str' in df.columns else 0
        unique_procs = df['comm'].nunique() if 'comm' in df.columns else 0
        unique_cpus = df['cpu'].nunique() if 'cpu' in df.columns else 0
        unique_numa = df['numa_node'].nunique() if 'numa_node' in df.columns else 0

        print(f"ã€æ¦‚è§ˆç»Ÿè®¡ã€‘")
        print(f"  æ€»é¡µé¢é”™è¯¯æ¬¡æ•°: {total_faults:,}")
        print(f"  é”™è¯¯ç±»åž‹æ•°: {unique_types}")
        print(f"  æ¶‰åŠè¿›ç¨‹æ•°: {unique_procs}")
        print(f"  æ¶‰åŠCPUæ•°: {unique_cpus}")
        print(f"  æ¶‰åŠNUMAèŠ‚ç‚¹æ•°: {unique_numa}")
        print(f"  å¹³å‡æ¯è¿›ç¨‹é¡µé¢é”™è¯¯: {total_faults / unique_procs:,.2f}" if unique_procs > 0 else "")

        # é¡µé¢é”™è¯¯ç±»åž‹å®Œæ•´åˆ†æž
        if 'fault_type_str' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€é¡µé¢é”™è¯¯ç±»åž‹å®Œæ•´åˆ†æžã€‘")
            print(f"{'=' * 100}")
            type_stats = df.groupby('fault_type_str')['count'].sum().sort_values(ascending=False)

            cumulative_pct = 0
            for i, (fault_type, count) in enumerate(type_stats.items(), 1):
                pct = (count / total_faults) * 100 if total_faults > 0 else 0
                cumulative_pct += pct
                print(f"  {i:3d}. {fault_type:40s} {count:12,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%]")

        # CPUè´Ÿè½½åˆ†æž
        if 'cpu' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€CPUé¡µé¢é”™è¯¯è´Ÿè½½åˆ†æžã€‘")
            print(f"{'=' * 100}")
            cpu_stats = df.groupby('cpu')['count'].sum().sort_values(ascending=False)
            avg_per_cpu = total_faults / len(cpu_stats) if len(cpu_stats) > 0 else 0

            print(f"  å¹³å‡æ¯CPUé¡µé¢é”™è¯¯æ•°: {avg_per_cpu:,.2f}")
            print(f"\nCPUé¡µé¢é”™è¯¯åˆ†å¸ƒ:")

            for cpu, count in cpu_stats.items():
                pct = (count / total_faults) * 100 if total_faults > 0 else 0
                ratio = count / avg_per_cpu if avg_per_cpu > 0 else 0
                deviation = ((count - avg_per_cpu) / avg_per_cpu * 100) if avg_per_cpu > 0 else 0

                # è´Ÿè½½æ ‡è®°
                if ratio > 2.0:
                    indicator = "ðŸ”¥ðŸ”¥"
                elif ratio > 1.5:
                    indicator = "ðŸ”¥ "
                elif ratio < 0.5:
                    indicator = "â„ï¸ "
                else:
                    indicator = "   "

                print(
                    f"  {indicator} CPU {cpu:3d}: {count:12,}æ¬¡ ({pct:5.2f}%) | è´Ÿè½½æ¯”: {ratio:5.2f}x | åå·®: {deviation:+6.1f}%")

        # NUMAèŠ‚ç‚¹åˆ†æž
        if 'numa_node' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€NUMAèŠ‚ç‚¹é¡µé¢é”™è¯¯åˆ†æžã€‘")
            print(f"{'=' * 100}")
            numa_stats = df.groupby('numa_node')['count'].sum().sort_values(ascending=False)

            for numa, count in numa_stats.items():
                pct = (count / total_faults) * 100 if total_faults > 0 else 0
                print(f"  NUMAèŠ‚ç‚¹ {numa}: {count:12,}æ¬¡ ({pct:6.2f}%)")

                # æ˜¾ç¤ºè¯¥NUMAèŠ‚ç‚¹ä¸Šçš„ä¸»è¦é”™è¯¯ç±»åž‹
                if 'fault_type_str' in df.columns:
                    numa_df = df[df['numa_node'] == numa]
                    numa_types = numa_df.groupby('fault_type_str')['count'].sum().sort_values(ascending=False).head(5)
                    for i, (fault_type, fcount) in enumerate(numa_types.items(), 1):
                        fpct = (fcount / count) * 100
                        print(f"      {i}. {fault_type:35s} {fcount:10,}æ¬¡ ({fpct:5.2f}%)")

        # è¿›ç¨‹å®Œæ•´æŽ’å
        if 'comm' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹é¡µé¢é”™è¯¯å®Œæ•´æŽ’åã€‘")
            print(f"{'=' * 100}")
            proc_stats = df.groupby('comm')['count'].sum().sort_values(ascending=False)

            cumulative_pct = 0
            for i, (comm, count) in enumerate(proc_stats.items(), 1):
                pct = (count / total_faults) * 100 if total_faults > 0 else 0
                cumulative_pct += pct
                print(f"  {i:3d}. {comm:35s} {count:12,}æ¬¡ ({pct:6.2f}%) [ç´¯è®¡: {cumulative_pct:6.2f}%]")

        # è¿›ç¨‹-é”™è¯¯ç±»åž‹å…³è”åˆ†æž
        if 'comm' in df.columns and 'fault_type_str' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€è¿›ç¨‹-é”™è¯¯ç±»åž‹å…³è”åˆ†æžã€‘(Top 15è¿›ç¨‹)")
            print(f"{'=' * 100}")

            top_procs = df.groupby('comm')['count'].sum().nlargest(15).index
            for comm in top_procs:
                comm_df = df[df['comm'] == comm]
                comm_total = comm_df['count'].sum()

                print(f"\nè¿›ç¨‹: {comm} (æ€»é¡µé¢é”™è¯¯: {comm_total:,}æ¬¡)")

                fault_dist = comm_df.groupby('fault_type_str')['count'].sum().sort_values(ascending=False)
                for i, (fault_type, count) in enumerate(fault_dist.items(), 1):
                    pct = (count / comm_total) * 100
                    print(f"  {i:2d}. {fault_type:40s} {count:10,}æ¬¡ ({pct:5.2f}%)")

        # CPU-é”™è¯¯ç±»åž‹å…³è”åˆ†æž
        if 'cpu' in df.columns and 'fault_type_str' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€CPU-é”™è¯¯ç±»åž‹å…³è”åˆ†æžã€‘(Top 10 CPU)")
            print(f"{'=' * 100}")

            top_cpus = df.groupby('cpu')['count'].sum().nlargest(10).index
            for cpu in top_cpus:
                cpu_df = df[df['cpu'] == cpu]
                cpu_total = cpu_df['count'].sum()

                print(f"\nCPU {cpu} (æ€»é¡µé¢é”™è¯¯: {cpu_total:,}æ¬¡)")

                fault_dist = cpu_df.groupby('fault_type_str')['count'].sum().sort_values(ascending=False)
                for i, (fault_type, count) in enumerate(fault_dist.items(), 1):
                    pct = (count / cpu_total) * 100
                    print(f"  {i:2d}. {fault_type:40s} {count:10,}æ¬¡ ({pct:5.2f}%)")

        # é¡µé¢é”™è¯¯é¢‘çŽ‡åˆ†å¸ƒ
        if 'fault_type_str' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€é¡µé¢é”™è¯¯é¢‘çŽ‡åˆ†å¸ƒã€‘")
            print(f"{'=' * 100}")

            fault_counts = df.groupby('fault_type_str')['count'].sum()

            ranges = [
                (1, 1000, "1-1,000æ¬¡"),
                (1001, 10000, "1,001-10,000æ¬¡"),
                (10001, 100000, "10,001-100,000æ¬¡"),
                (100001, 1000000, "100,001-1,000,000æ¬¡"),
                (1000001, 10000000, "1,000,001-10,000,000æ¬¡"),
                (10000001, float('inf'), "10,000,000æ¬¡ä»¥ä¸Š")
            ]

            for min_count, max_count, label in ranges:
                if max_count == float('inf'):
                    faults_in_range = fault_counts[fault_counts >= min_count]
                else:
                    faults_in_range = fault_counts[(fault_counts >= min_count) & (fault_counts <= max_count)]

                fault_num = len(faults_in_range)
                count_num = faults_in_range.sum()
                fault_pct = (fault_num / unique_types * 100) if unique_types > 0 else 0
                count_pct = (count_num / total_faults * 100) if total_faults > 0 else 0

                print(
                    f"  {label:30s} é”™è¯¯ç±»åž‹: {fault_num:3d} ({fault_pct:5.2f}%)  é”™è¯¯æ¬¡æ•°: {count_num:12,} ({count_pct:6.2f}%)")

        # CPUè´Ÿè½½å‡è¡¡åˆ†æž
        if 'cpu' in df.columns and 'count' in df.columns:
            print(f"\n{'=' * 100}")
            print(f"ã€CPUè´Ÿè½½å‡è¡¡åˆ†æžã€‘")
            print(f"{'=' * 100}")

            cpu_counts = df.groupby('cpu')['count'].sum()
            max_load = cpu_counts.max()
            min_load = cpu_counts.min()
            avg_load = cpu_counts.mean()
            std_load = cpu_counts.std()

            print(f"  æœ€å¤§è´Ÿè½½CPU: {cpu_counts.idxmax()} ({max_load:,}æ¬¡)")
            print(f"  æœ€å°è´Ÿè½½CPU: {cpu_counts.idxmin()} ({min_load:,}æ¬¡)")
            print(f"  å¹³å‡è´Ÿè½½: {avg_load:,.2f}æ¬¡")
            print(f"  æ ‡å‡†å·®: {std_load:,.2f}")
            print(f"  è´Ÿè½½å·®å¼‚: {max_load - min_load:,}æ¬¡ ({(max_load - min_load) / avg_load * 100:.1f}%)")
            print(f"  è´Ÿè½½æ¯”: {max_load / min_load:.2f}x" if min_load > 0 else "")

            # è´Ÿè½½å‡è¡¡åº¦è¯„ä¼°
            balance_score = 1 - (std_load / avg_load) if avg_load > 0 else 0
            if balance_score > 0.9:
                balance_level = "ä¼˜ç§€ âœ“"
            elif balance_score > 0.7:
                balance_level = "è‰¯å¥½"
            elif balance_score > 0.5:
                balance_level = "ä¸€èˆ¬"
            else:
                balance_level = "è¾ƒå·® âš ï¸"

            print(f"\n  è´Ÿè½½å‡è¡¡åº¦: {balance_score * 100:.1f}% ({balance_level})")


if __name__ == '__main__':
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='eBPFæ•°æ®åˆ†æžå·¥å…· - é€‚é…æ–°çš„èšåˆç»Ÿè®¡æ ¼å¼')
    parser.add_argument('--daily-dir', default='./daily_data', help='é¢„å¤„ç†æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--reports-dir', default='./reports', help='åˆ†æžæŠ¥å‘Šè¾“å‡ºç›®å½•')
    parser.add_argument('--date', required=True, help='åˆ†æžæ—¥æœŸï¼Œæ ¼å¼: YYYYMMDD')
    parser.add_argument('--type', choices=['exec', 'bio', 'func', 'open', 'syscall', 'interrupt', 'page_fault', 'all'],
                        default='all', help='ç›‘æŽ§å™¨ç±»åž‹')
    parser.add_argument('--hostname', help='æŒ‡å®šä¸»æœºåï¼ˆé»˜è®¤ä½¿ç”¨å½“å‰ä¸»æœºåï¼‰')

    args = parser.parse_args()

    analyzer = EBPFAnalyzer(args.daily_dir, args.reports_dir, hostname=args.hostname)

    # æ‰§è¡Œåˆ†æž
    if args.type == 'all':
        # åˆ†æžæ‰€æœ‰ç±»åž‹
        for monitor_type in analyzer.monitor_types:
            try:
                method = getattr(analyzer, f'analyze_{monitor_type}')
                method(args.date)
            except Exception as e:
                logger.error(f"åˆ†æž{monitor_type}æ—¶å‡ºé”™: {e}")
    else:
        # åˆ†æžæŒ‡å®šç±»åž‹
        try:
            method = getattr(analyzer, f'analyze_{args.type}')
            method(args.date)
        except Exception as e:
            logger.error(f"åˆ†æž{args.type}æ—¶å‡ºé”™: {e}")
